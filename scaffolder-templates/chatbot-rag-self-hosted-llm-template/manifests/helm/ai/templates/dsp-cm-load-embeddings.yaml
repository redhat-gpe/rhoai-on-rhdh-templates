kind: ConfigMap
metadata:
  name: {{ .Values.app.name }}-embeddings
apiVersion: v1
data:
  ingest_embeddings.ipynb: |
    {
    "cells": [
      {
      "cell_type": "markdown",
      "id": "3420575b-4d00-458b-aa0e-7030008ccd53",
      "metadata": {},
      "source": [
        "## Creating an index and populating it with documents using PostgreSQL+pgvector\n",
        "\n",
        "Simple example on how to ingest PDF documents, then web pages content into a PostgreSQL+pgvector VectorStore.\n",
        "\n",
        "Requirements:\n",
        "- A PostgreSQL cluster with the pgvector extension installed (https://github.com/pgvector/pgvector)\n",
        "- A Database created in the cluster with the extension enabled (in this example, the database is named `vectordb`. Run the following command in the database as a superuser:\n",
        "`CREATE EXTENSION vector;`\n",
        "\n",
        "Note: if your PostgreSQL is deployed on OpenShift, directly from inside the Pod (Terminal view on the Console, or using `oc rsh` to log into the Pod), you can run the command: `psql -d vectordb -c \"CREATE EXTENSION vector;\"`\n"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "8308b229-b520-4e82-a783-eb921bb955e7",
      "metadata": {},
      "source": [
        "### Needed packages"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 1,
      "id": "91e41b41-f60a-4b0f-91a1-cd273b60f21b",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
        "name": "stdout",
        "output_type": "stream",
        "text": [
          "\n",
          "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
          "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
        ]
        }
      ],
      "source": [
        "!pip install -q pgvector"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "1a82063d-6153-4812-8977-042241736b53",
      "metadata": {},
      "source": [
        "### Base parameters, the PostgreSQL info"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 2,
      "id": "417ed4a4-9418-4f48-bebd-ef0ea11ae434",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "product_version = 2.6\n",
        "CONNECTION_STRING = \"postgresql+psycopg://vectordb:vectordb@postgresql.{{ .Values.app.namespace }}.svc.cluster.local:5432/vectordb\"\n", # notsecret
        "COLLECTION_NAME = f\"rhoai-doc-{product_version}\""
      ]
      },
      {
      "cell_type": "markdown",
      "id": "9b499a49-128c-4be5-903b-76c40771c7bc",
      "metadata": {
        "tags": []
      },
      "source": [
        "#### Imports"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 3,
      "id": "600cd763-6ecc-4c77-89c0-47108c31c44e",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
        "name": "stderr",
        "output_type": "stream",
        "text": [
          "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
          "/tmp/ipykernel_2987/2879674956.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
          "  from tqdm.autonotebook import tqdm, trange\n"
        ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader, WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores.pgvector import PGVector\n",
        "from tqdm.autonotebook import tqdm, trange"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "f68f6785-480e-4519-be4f-8e1738dba4ca",
      "metadata": {},
      "source": [
        "## Initial index creation and document ingestion"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "f8cff5f7-c509-48db-90b5-e15815b8b530",
      "metadata": {},
      "source": [
        "#### Download and load pdfs"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bc4fe0db-f494-4cbd-9e97-8b6359a78cb7",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"release_notes\",\n",
        "    \"introduction_to_red_hat_openshift_ai\",\n",
        "    \"getting_started_with_red_hat_openshift_ai_self-managed\",\n",
        "    \"openshift_ai_tutorial_-_fraud_detection_example\",\n",
        "    \"developing_a_model\",\n",
        "    \"integrating_data_from_amazon_s3\",\n",
        "    \"working_on_data_science_projects\",\n",
        "    \"serving_models\",\n",
        "    \"monitoring_data_science_models\",\n",
        "    \"managing_users\",\n",
        "    \"managing_resources\",\n",
        "    \"installing_and_uninstalling_openshift_ai_self-managed\",\n",
        "    \"installing_and_uninstalling_openshift_ai_self-managed_in_a_disconnected_environment\",\n",
        "    \"upgrading_openshift_ai_self-managed\",\n",
        "    \"upgrading_openshift_ai_self-managed_in_a_disconnected_environment\",   \n",
        "]\n",
        "\n",
        "pdfs = [f\"https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/{product_version}/pdf/{doc}/red_hat_openshift_ai_self-managed-{product_version}-{doc}-en-us.pdf\" for doc in documents]\n",
        "pdfs_to_urls = {f\"red_hat_openshift_ai_self-managed-{product_version}-{doc}-en-us\": f\"https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/{product_version}/html-single/{doc}/index\" for doc in documents}"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3eea5acc-49df-41c9-a01a-0cdbca96e8e2",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
        "name": "stdout",
        "output_type": "stream",
        "text": [
          "['https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/release_notes/red_hat_openshift_ai_self-managed-2.6-release_notes-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/introduction_to_red_hat_openshift_ai/red_hat_openshift_ai_self-managed-2.6-introduction_to_red_hat_openshift_ai-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/getting_started_with_red_hat_openshift_ai_self-managed/red_hat_openshift_ai_self-managed-2.6-getting_started_with_red_hat_openshift_ai_self-managed-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/openshift_ai_tutorial_-_fraud_detection_example/red_hat_openshift_ai_self-managed-2.6-openshift_ai_tutorial_-_fraud_detection_example-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/developing_a_model/red_hat_openshift_ai_self-managed-2.6-developing_a_model-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/integrating_data_from_amazon_s3/red_hat_openshift_ai_self-managed-2.6-integrating_data_from_amazon_s3-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/working_on_data_science_projects/red_hat_openshift_ai_self-managed-2.6-working_on_data_science_projects-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/serving_models/red_hat_openshift_ai_self-managed-2.6-serving_models-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/monitoring_data_science_models/red_hat_openshift_ai_self-managed-2.6-monitoring_data_science_models-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/managing_users/red_hat_openshift_ai_self-managed-2.6-managing_users-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/managing_resources/red_hat_openshift_ai_self-managed-2.6-managing_resources-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/installing_and_uninstalling_openshift_ai_self-managed/red_hat_openshift_ai_self-managed-2.6-installing_and_uninstalling_openshift_ai_self-managed-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/installing_and_uninstalling_openshift_ai_self-managed_in_a_disconnected_environment/red_hat_openshift_ai_self-managed-2.6-installing_and_uninstalling_openshift_ai_self-managed_in_a_disconnected_environment-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/upgrading_openshift_ai_self-managed/red_hat_openshift_ai_self-managed-2.6-upgrading_openshift_ai_self-managed-en-us.pdf', 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/upgrading_openshift_ai_self-managed_in_a_disconnected_environment/red_hat_openshift_ai_self-managed-2.6-upgrading_openshift_ai_self-managed_in_a_disconnected_environment-en-us.pdf']\n",
          "Skipped https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/pdf/monitoring_data_science_models/red_hat_openshift_ai_self-managed-2.6-monitoring_data_science_models-en-us.pdf\n"
        ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "docs_dir = f\"rhoai-doc-{product_version}\"\n",
        "print(pdfs)\n",
        "\n",
        "if not os.path.exists(docs_dir):\n",
        "    os.mkdir(docs_dir)\n",
        "\n",
        "for pdf in pdfs:\n",
        "    try:\n",
        "        response = requests.get(pdf)\n",
        "    except:\n",
        "        print(f\"Skipped {pdf}\")\n",
        "        continue\n",
        "    if response.status_code!=200:\n",
        "        print(f\"Skipped {pdf}\")\n",
        "        continue  \n",
        "    with open(f\"{docs_dir}/{pdf.split('/')[-1]}\", 'wb') as f:\n",
        "        f.write(response.content)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 6,
      "id": "af4074d4-eff4-45b2-902d-ec8c075a83ef",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "pdf_folder_path = f\"./rhoai-doc-{product_version}\"\n",
        "\n",
        "pdf_loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
        "pdf_docs = pdf_loader.load()"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "cde7ed3a-0530-47a1-95c2-22db6c782a95",
      "metadata": {},
      "source": [
        "#### Inject metadata"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 7,
      "id": "702230f6-e6d3-44c7-a643-4996387606ff",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "for doc in pdf_docs:\n",
        "    doc.metadata[\"source\"] = pdfs_to_urls[Path(doc.metadata[\"source\"]).stem]"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "dd511d44-2d92-47a0-9163-b25576c9557b",
      "metadata": {
        "tags": []
      },
      "source": [
        "#### Load websites"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8aebf003-d7ec-43ba-8e04-1931bcff2866",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "websites = [\n",
        "    \"https://ai-on-openshift.io/getting-started/openshift/\",\n",
        "    \"https://ai-on-openshift.io/getting-started/opendatahub/\",\n",
        "    \"https://ai-on-openshift.io/getting-started/openshift-ai/\",\n",
        "    \"https://ai-on-openshift.io/odh-rhoai/configuration/\",\n",
        "    \"https://ai-on-openshift.io/odh-rhoai/custom-notebooks/\",\n",
        "    \"https://ai-on-openshift.io/odh-rhoai/nvidia-gpus/\",\n",
        "    \"https://ai-on-openshift.io/odh-rhoai/custom-runtime-triton/\",\n",
        "    \"https://ai-on-openshift.io/odh-rhoai/openshift-group-management/\",\n",
        "    \"https://ai-on-openshift.io/tools-and-applications/minio/minio/\",\n",
        "    \"https://docs.redhat.com/articles/7047935\",\n",
        "    \"https://docs.redhat.com/articles/rhoai-supported-configs\",\n",
        "]"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 9,
      "id": "99f41110-8ca7-4d90-93b2-3b5021c894b8",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "website_loader = WebBaseLoader(websites)\n",
        "website_docs = website_loader.load()"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "157ddd29-54b3-474a-9b10-2d274bc3254f",
      "metadata": {},
      "source": [
        "#### Merge both types of docs"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8d361094-8b43-4351-8495-37628c35c42d",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "docs = pdf_docs + website_docs"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "4198fe0a-38bf-4cd4-af7d-35b41c645edd",
      "metadata": {},
      "source": [
        "#### Split documents into chunks with some overlap"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 11,
      "id": "edba4a08-2194-4df1-9091-6f2b596757a1",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
        "data": {
          "text/plain": [
          "Document(metadata={'source': 'https://docs.redhat.com/en-us/documentation/red_hat_openshift_ai_self-managed/2.6/html-single/openshift_ai_tutorial_-_fraud_detection_example/index', 'page': 0}, page_content='Red Hat OpenShift AI Self-Managed\\n \\n2.6\\nOpenShift AI tutorial - Fraud detection\\nexample\\nLast Updated: 2024-02-26')"
          ]
        },
        "execution_count": 11,
        "metadata": {},
        "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024,\n",
        "                                               chunk_overlap=40)\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "all_splits[0]"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "6884f070",
      "metadata": {},
      "source": [
        "#### Cleanup documents as PostgreSQL won't accept the NUL character, '\\x00', in TEXT fields."
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5aefc08d-a4ad-4aad-9120-cfa98b67cbe2",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "for doc in all_splits:\n",
        "    doc.page_content = doc.page_content.replace('\\x00', '')"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "7ae7eae2-c670-4eb5-803b-b4d591fa83db",
      "metadata": {
        "tags": []
      },
      "source": [
        "#### Create the index and ingest the documents"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
        "name": "stderr",
        "output_type": "stream",
        "text": [
          "/opt/app-root/lib64/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
          "  warnings.warn(\n",
          "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
          "To disable this warning, you can either:\n",
          "\t- Avoid using `tokenizers` before the fork if possible\n",
          "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
          "To disable this warning, you can either:\n",
          "\t- Avoid using `tokenizers` before the fork if possible\n",
          "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "/opt/app-root/lib64/python3.9/site-packages/langchain_community/vectorstores/pgvector.py:328: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
          "  warn_deprecated(\n"
        ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "db = PGVector.from_documents(\n",
        "    documents=all_splits,\n",
        "    embedding=embeddings,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    connection_string=CONNECTION_STRING,\n",
        "    #pre_delete_collection=True # This deletes existing collection and its data, use carefully!\n",
        ")"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "7a3d987b-8ebc-46ce-a206-48c1339b7a5b",
      "metadata": {},
      "source": [
        "#### Alternatively, add new documents"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c37f227d-a13d-456c-b91b-3c203e62fc0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# db = PGVector(\n",
        "#     connection_string=CONNECTION_STRING,\n",
        "#     collection_name=COLLECTION_NAME,\n",
        "#     embedding_function=embeddings)\n",
        "\n",
        "# db.add_documents(all_splits)"
      ]
      },
      {
      "cell_type": "markdown",
      "id": "dae3b458-4979-46df-8493-7496764a2568",
      "metadata": {},
      "source": [
        "#### Test query"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 17,
      "id": "489c6e6d-c42c-4de4-87cf-8edfd0e63da3",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "query = \"How can I work with GPU and taints in OpenShift AI?\"\n",
        "docs_with_score = db.similarity_search_with_score(query)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": 16,
      "id": "90feeb37-7888-4c5f-a5cb-5f82637cec16",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
        "name": "stdout",
        "output_type": "stream",
        "text": [
          "--------------------------------------------------------------------------------\n",
          "Score:  0.2988101809153094\n",
          "Apply the taints you need to your Nodes or MachineSets, for example:\n",
          "apiVersion: machine.openshift.io/v1beta1\n",
          "kind: MachineSet\n",
          "metadata:\n",
          "  ...\n",
          "spec:\n",
          "  replicas: 1\n",
          "  selector:\n",
          "    ...\n",
          "  template:\n",
          "    ...\n",
          "    spec:\n",
          "      ...\n",
          "      taints:\n",
          "        - key: restrictedaccess\n",
          "          value: \"yes\"\n",
          "          effect: NoSchedule\n",
          "\n",
          "\n",
          "\n",
          "Apply the relevant toleration to the NVIDIA Operator.\n",
          "\n",
          "\n",
          "In the nvidia-gpu-operator namespace, get to the Installed Operator menu, open the NVIDIA GPU Operator settings, get to the ClusterPolicy tab, and edit the ClusterPolicy.\n",
          "--------------------------------------------------------------------------------\n",
          "--------------------------------------------------------------------------------\n",
          "Score:  0.3214550422754846\n",
          "CHAPTER 9. ENABLING GPU SUPPORT IN OPENSHIFT AI\n",
          "Optionally, to ensure that your data scientists can use compute-heavy workloads in their models, you\n",
          "can enable graphics processing units (GPUs) in OpenShift AI.\n",
          "Prerequisites\n",
          "You have logged in to your OpenShift Container Platform cluster.\n",
          "You have the \n",
          "cluster-admin\n",
          " role in your OpenShift Container Platform cluster.\n",
          "Procedure\n",
          "1\n",
          ". \n",
          "To enable GPU support on an OpenShift cluster in a disconnected or airgapped environment,\n",
          "follow the instructions here: \n",
          "Deploy GPU Operators in a disconnected or airgapped\n",
          "environment\n",
          " in the NVIDIA documentation.\n",
          "2\n",
          ". \n",
          "Delete the \n",
          "migration-gpu-status\n",
          " ConfigMap.\n",
          "a\n",
          ". \n",
          "In the OpenShift Container Platform web console, switch to the \n",
          "Administrator\n",
          " perspective.\n",
          "b\n",
          ". \n",
          "Set the \n",
          "Project\n",
          " to \n",
          "All Projects\n",
          " or \n",
          "redhat-ods-applications\n",
          " to ensure you can see the\n",
          "appropriate ConfigMap.\n",
          "c\n",
          ". \n",
          "Search for the \n",
          "migration-gpu-status\n",
          " ConfigMap.\n",
          "d\n",
          ". \n",
          "Click the action menu (\n",
          "â‹®\n",
          ") and select \n",
          "Delete ConfigMap\n",
          " from the list.\n",
          "The \n",
          "Delete ConfigMap\n",
          "--------------------------------------------------------------------------------\n",
          "--------------------------------------------------------------------------------\n",
          "Score:  0.3263350524406148\n",
          "But don't worry, OpenShift AI and Open Data Hub take care of this part for you when you launch notebooks, workbenches, model servers, or pipeline runtimes!\n",
          "Installation\n",
          "Here is the documentation you can follow:\n",
          "\n",
          "OpenShift AI documentation\n",
          "NVIDIA documentation (more detailed)\n",
          "\n",
          "Advanced configuration\n",
          "Working with taints\n",
          "In many cases, you will want to restrict access to GPUs, or be able to provide choice between different types of GPUs: simply stating \"I want a GPU\" is not enough. Also, if you want to make sure that only the Pods requiring GPUs end up on GPU-enabled nodes (and not other Pods that just end up being there at random because that's how Kubernetes works...), you're at the right place!\n",
          "The only supported method at the moment to achieve this is to taint nodes, then apply tolerations on the Pods depending on where you want them scheduled. If you don't pay close attention though when applying taints on Nodes, you may end up with the NVIDIA drivers not installed on those nodes...\n",
          "In this case you must:\n",
          "--------------------------------------------------------------------------------\n",
          "--------------------------------------------------------------------------------\n",
          "Score:  0.3432605266571045\n",
          "CHAPTER 9. ENABLING GPU SUPPORT IN OPENSHIFT AI\n",
          "Optionally, to ensure that your data scientists can use compute-heavy workloads in their models, you\n",
          "can enable graphics processing units (GPUs) in OpenShift AI.\n",
          "IMPORTANT\n",
          "If you are using OpenShift AI in a disconnected self-managed environment, see \n",
          "Enabling\n",
          "GPU support in OpenShift AI\n",
          " instead.\n",
          "Prerequisites\n",
          "You have logged in to your OpenShift Container Platform cluster.\n",
          "You have the \n",
          "cluster-admin\n",
          " role in your OpenShift Container Platform cluster.\n",
          "Procedure\n",
          "1\n",
          ". \n",
          "To enable GPU support on an OpenShift cluster, follow the instructions here: \n",
          "NVIDIA GPU\n",
          "Operator on Red Hat OpenShift Container Platform\n",
          " in the NVIDIA documentation.\n",
          "2\n",
          ". \n",
          "Delete the \n",
          "migration-gpu-status\n",
          " ConfigMap.\n",
          "a\n",
          ". \n",
          "In the OpenShift Container Platform web console, switch to the \n",
          "Administrator\n",
          " perspective.\n",
          "b\n",
          ". \n",
          "Set the \n",
          "Project\n",
          " to \n",
          "All Projects\n",
          " or \n",
          "redhat-ods-applications\n",
          " to ensure you can see the\n",
          "appropriate ConfigMap.\n",
          "c\n",
          ". \n",
          "Search for the \n",
          "migration-gpu-status\n",
          " ConfigMap.\n",
          "d\n",
          ".\n",
          "--------------------------------------------------------------------------------\n"
        ]
        }
      ],
      "source": [
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "id": "40430359-e786-45f5-bc8a-b1bc141de93b",
      "metadata": {},
      "outputs": [],
      "source": []
      }
    ],
    "metadata": {
      "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
      },
      "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 5
    }